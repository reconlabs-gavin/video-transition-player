import cv2
import numpy as np
from pathlib import Path
import os
from transitions import create_transition

class VideoPlayer:
    def __init__(self, video_folder='videos'):
        self.video_folder = video_folder
        self.videos = self.load_videos()
        self.current_index = 0
        self.transition_frames = 20  # ì „í™˜ í”„ë ˆìž„ ìˆ˜
        self.show_ui = True  # UI í‘œì‹œ ì—¬ë¶€
        self.display_size = (720, 1280)  # í‘œì‹œ í¬ê¸° (width, height)
        # ê¸°ë³¸ ì „í™˜ íš¨ê³¼ (slide). í•„ìš”ì‹œ ë‹¤ë¥¸ íš¨ê³¼ë¡œ êµì²´ ê°€ëŠ¥
        self.transition = create_transition('slide', direction='down')
        
        # ë§ˆìš°ìŠ¤ ë“œëž˜ê·¸ ìƒíƒœ
        self.mouse_down = False
        self.mouse_start_y = 0
        self.swipe_threshold = 100  # ìŠ¤ì™€ì´í”„ ê°ì§€ ìµœì†Œ ê±°ë¦¬ (í”½ì…€)
        self.swipe_action = None  # 'next', 'prev', or None
        
    def load_videos(self):
        """videos í´ë”ì—ì„œ ë™ì˜ìƒ íŒŒì¼ ë¡œë“œ"""
        # ì§€ì› í™•ìž¥ìžì— mp3 ì¶”ê°€ (ì˜¤ë””ì˜¤ íŒŒì¼ì€ ì•„ëž˜ ê²€ì‚¬ì—ì„œ ìžë™ ì œì™¸)
        video_extensions = ['.mp4', '.avi', '.mov', '.mkv', '.mp3']
        candidates = [str(f) for f in Path(self.video_folder).glob('*')
                      if f.suffix.lower() in video_extensions]

        # OpenCVë¡œ ì‹¤ì œ ìž¬ìƒ ê°€ëŠ¥í•œ ë¹„ë””ì˜¤ë§Œ í•„í„°ë§
        valid_videos = []
        for path in sorted(candidates):
            cap = cv2.VideoCapture(path)
            if cap.isOpened():
                frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
                width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
                height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
                if frame_count > 0 and width > 0 and height > 0:
                    valid_videos.append(path)
            cap.release()

        return valid_videos
    
    # ìŠ¬ë¼ì´ë“œ ì „í™˜ ë¡œì§ì€ transitions ëª¨ë“ˆë¡œ ë¶„ë¦¬ë˜ì—ˆìŠµë‹ˆë‹¤.
    
    def resize_with_aspect_ratio(self, frame, target_size):
        """
        ë¹„ë””ì˜¤ ë¹„ìœ¨ì„ ìœ ì§€í•˜ë©´ì„œ ë¦¬ì‚¬ì´ì¦ˆ (letterbox/pillarbox)
        """
        target_w, target_h = target_size
        h, w = frame.shape[:2]

        # ë¹„ìœ¨ ê³„ì‚°
        ratio = min(target_w / w, target_h / h)
        new_w = int(w * ratio)
        new_h = int(h * ratio)

        # ë¦¬ì‚¬ì´ì¦ˆ
        resized = cv2.resize(frame, (new_w, new_h), interpolation=cv2.INTER_LINEAR)

        # ê²€ì€ ë°°ê²½ì— ì¤‘ì•™ ì •ë ¬
        result = np.zeros((target_h, target_w, 3), dtype=np.uint8)
        x_offset = (target_w - new_w) // 2
        y_offset = (target_h - new_h) // 2
        result[y_offset:y_offset + new_h, x_offset:x_offset + new_w] = resized

        return result
    def get_frame(self, cap, target_size):
        """ë¹„ë””ì˜¤ì—ì„œ í”„ë ˆìž„ ì½ê¸° ë° ë¦¬ì‚¬ì´ì¦ˆ"""
        ret, frame = cap.read()
        if not ret:
            return None
        return self.resize_with_aspect_ratio(frame, target_size)
    
    def draw_ui_overlay(self, frame, video_name, current_frame, total_frames):
        """
        í™”ë©´ì— UI ì˜¤ë²„ë ˆì´ ì¶”ê°€
        - ìƒë‹¨: í˜„ìž¬ ì˜ìƒ ì´ë¦„
        - í•˜ë‹¨: ì§„í–‰ë„ ë°”, ì¡°ìž‘ ížŒíŠ¸
        """
        if not self.show_ui:
            return frame
        
        overlay = frame.copy()
        h, w = frame.shape[:2]
        
        # ë°˜íˆ¬ëª… ë°°ê²½ - ìƒë‹¨
        cv2.rectangle(overlay, (0, 0), (w, 100), (0, 0, 0), -1)
        # ë°˜íˆ¬ëª… ë°°ê²½ - í•˜ë‹¨
        cv2.rectangle(overlay, (0, h-120), (w, h), (0, 0, 0), -1)
        
        # ë¸”ë Œë”©
        frame = cv2.addWeighted(frame, 0.7, overlay, 0.3, 0)
        
        # ìƒë‹¨: ì˜ìƒ ì´ë¦„
        font = cv2.FONT_HERSHEY_SIMPLEX
        video_name_short = os.path.basename(video_name)
        if len(video_name_short) > 40:
            video_name_short = video_name_short[:37] + "..."
        
        cv2.putText(frame, video_name_short, (20, 40), 
                   font, 0.7, (255, 255, 255), 2, cv2.LINE_AA)
        
        # ì˜ìƒ ë²ˆí˜¸ í‘œì‹œ
        video_info = f"{self.current_index + 1}/{len(self.videos)}"
        cv2.putText(frame, video_info, (20, 75), 
                   font, 0.6, (180, 180, 180), 1, cv2.LINE_AA)
        
        # ì§„í–‰ë„ ë°”
        progress = current_frame / max(total_frames, 1)
        bar_y = h - 90
        bar_width = w - 40
        bar_height = 8
        
        # ë°°ê²½ ë°” (íšŒìƒ‰)
        cv2.rectangle(frame, (20, bar_y), (20 + bar_width, bar_y + bar_height), 
                     (80, 80, 80), -1)
        
        # ì§„í–‰ ë°” (í°ìƒ‰)
        progress_width = int(bar_width * progress)
        if progress_width > 0:
            cv2.rectangle(frame, (20, bar_y), (20 + progress_width, bar_y + bar_height), 
                         (255, 255, 255), -1)
        
        # ì‹œê°„ í‘œì‹œ
        current_time = current_frame / max(total_frames, 1) * (total_frames / 30)  # ëŒ€ëžµì ì¸ ì‹œê°„
        time_text = f"{int(current_time)}s"
        cv2.putText(frame, time_text, (w - 100, bar_y + bar_height + 25), 
                   font, 0.5, (180, 180, 180), 1, cv2.LINE_AA)
        
        # í•˜ë‹¨: ì¡°ìž‘ ížŒíŠ¸
        hints = [
            ("â†‘/W", "ì´ì „"),
            ("â†“/S", "ë‹¤ìŒ"),
            ("Space", "ì¼ì‹œì •ì§€"),
            ("H", "UI ìˆ¨ê¹€"),
            ("Q", "ì¢…ë£Œ")
        ]
        
        x_start = 20
        y_pos = h - 40
        for key, action in hints:
            text = f"{key}: {action}"
            cv2.putText(frame, text, (x_start, y_pos), 
                       font, 0.45, (200, 200, 200), 1, cv2.LINE_AA)
            x_start += 130
        
        return frame
    
    def mouse_callback(self, event, x, y, flags, param):
        """ë§ˆìš°ìŠ¤ ë“œëž˜ê·¸ ìŠ¤ì™€ì´í”„ ì²˜ë¦¬"""
        if event == cv2.EVENT_LBUTTONDOWN:
            self.mouse_down = True
            self.mouse_start_y = y
            self.swipe_action = None
        
        elif event == cv2.EVENT_LBUTTONUP:
            if self.mouse_down:
                delta_y = y - self.mouse_start_y
                if abs(delta_y) >= self.swipe_threshold:
                    if delta_y < 0:
                        # ë“œëž˜ê·¸ ìœ„ë¡œ â†’ ë‹¤ìŒ ì˜ìƒ
                        self.swipe_action = 'next'
                    else:
                        # ë“œëž˜ê·¸ ì•„ëž˜ë¡œ â†’ ì´ì „ ì˜ìƒ
                        self.swipe_action = 'prev'
            self.mouse_down = False
    
    def play(self):
        """ë¹„ë””ì˜¤ ìž¬ìƒ ë©”ì¸ ë£¨í”„"""
        if not self.videos:
            print("videos í´ë”ì— ë™ì˜ìƒ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤!")
            return
        
        print(f"\n{'='*60}")
        print(f"  Video Transition Player")
        print(f"{'='*60}")
        print(f"ì´ {len(self.videos)}ê°œì˜ ë™ì˜ìƒ ë°œê²¬\n")
        
        for i, video in enumerate(self.videos):
            print(f"  {i+1}. {os.path.basename(video)}")
        
        print(f"\n{'='*60}")
        print("ì¡°ìž‘ë²•:")
        print("  â†‘ / W    : ì´ì „ ì˜ìƒ")
        print("  â†“ / S    : ë‹¤ìŒ ì˜ìƒ")
        print("  ë§ˆìš°ìŠ¤ ë“œëž˜ê·¸ â†‘ : ë‹¤ìŒ ì˜ìƒ")
        print("  ë§ˆìš°ìŠ¤ ë“œëž˜ê·¸ â†“ : ì´ì „ ì˜ìƒ")
        print("  Space    : ì¼ì‹œì •ì§€/ìž¬ìƒ")
        print("  H        : UI í‘œì‹œ/ìˆ¨ê¹€")
        print("  Q        : ì¢…ë£Œ")
        print(f"{'='*60}\n")
        
        cap = cv2.VideoCapture(self.videos[self.current_index])
        fps = int(cap.get(cv2.CAP_PROP_FPS))
        if fps <= 0:
            fps = 30  # ê¸°ë³¸ê°’
        
        total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
        
        # ìœˆë„ìš° ì„¤ì •
        window_name = 'Video Player'
        cv2.namedWindow(window_name, cv2.WINDOW_NORMAL)
        cv2.resizeWindow(window_name, self.display_size[0], self.display_size[1])
        # ë§ˆìš°ìŠ¤ ì½œë°± ë“±ë¡
        cv2.setMouseCallback(window_name, self.mouse_callback)
        # ì°½ì„ ìµœìƒìœ„ë¡œ ì„¤ì • (í¬ì»¤ìŠ¤ ë¬¸ì œ í•´ê²°)
        cv2.setWindowProperty(window_name, cv2.WND_PROP_TOPMOST, 1)
        print("âš ï¸  OpenCV ì°½ì„ í´ë¦­í•˜ì—¬ í¬ì»¤ìŠ¤ë¥¼ ë§žì¶˜ í›„ í‚¤ë¥¼ ëˆŒëŸ¬ì£¼ì„¸ìš”!\n")
        print("ðŸ–±ï¸  ë§ˆìš°ìŠ¤ ë“œëž˜ê·¸ë¡œë„ ì˜ìƒ ì „í™˜ì´ ê°€ëŠ¥í•©ë‹ˆë‹¤!\n")
        
        paused = False
        
        while True:
            if not paused:
                ret, frame = cap.read()
                
                # í˜„ìž¬ ë¹„ë””ì˜¤ ëë‚˜ë©´ ì²˜ìŒë¶€í„° ë°˜ë³µ
                if not ret:
                    cap.set(cv2.CAP_PROP_POS_FRAMES, 0)
                    ret, frame = cap.read()
                
                if ret:
                    # ë¹„ìœ¨ ìœ ì§€í•˜ë©° ë¦¬ì‚¬ì´ì¦ˆ
                    frame = self.resize_with_aspect_ratio(frame, self.display_size)
                    
                    # UI ì˜¤ë²„ë ˆì´ ì¶”ê°€
                    current_frame = int(cap.get(cv2.CAP_PROP_POS_FRAMES))
                    frame = self.draw_ui_overlay(
                        frame, 
                        self.videos[self.current_index],
                        current_frame,
                        total_frames
                    )
                    
                    cv2.imshow(window_name, frame)
            
            # í‚¤ ìž…ë ¥ ëŒ€ê¸° (íŠ¹ìˆ˜í‚¤ í¬í•¨)
            wait_time = 1 if paused else int(1000 / fps)
            key = cv2.waitKeyEx(wait_time)
            
            # ë§ˆìš°ìŠ¤ ìŠ¤ì™€ì´í”„ ì²˜ë¦¬
            if self.swipe_action == 'next':
                next_index = (self.current_index + 1) % len(self.videos)
                self.transition_to_video(cap, next_index, 'down')
                cap.release()
                cap = cv2.VideoCapture(self.videos[next_index])
                total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
                self.current_index = next_index
                paused = False
                print(f"ðŸ–±ï¸ â†’ {os.path.basename(self.videos[self.current_index])}")
                self.swipe_action = None
            elif self.swipe_action == 'prev':
                prev_index = (self.current_index - 1) % len(self.videos)
                self.transition_to_video(cap, prev_index, 'up')
                cap.release()
                cap = cv2.VideoCapture(self.videos[prev_index])
                total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
                self.current_index = prev_index
                paused = False
                print(f"ðŸ–±ï¸ â† {os.path.basename(self.videos[self.current_index])}")
                self.swipe_action = None
            
            # ë””ë²„ê¹… - í‚¤ ì½”ë“œ ì¶œë ¥ (ì›ë³¸ê³¼ ë§ˆìŠ¤í‚¹ ë²„ì „ ëª¨ë‘)
            if key != -1 and key != 255:
                masked = key & 0xFF
                ch = chr(masked) if 32 <= masked <= 126 else 'N/A'
                print(f"Key pressed: {key}, masked: {masked}, char: {ch}")
            
            # ë‹¤ìŒ ì˜ìƒ (s ë˜ëŠ” ì•„ëž˜ í™”ì‚´í‘œ)
            # ì†Œë¬¸ìž/ëŒ€ë¬¸ìž ëª¨ë‘ í™•ì¸, í™”ì‚´í‘œëŠ” ë‹¤ì–‘í•œ ì½”ë“œ ì‹œë„
            # ë‹¤ìŒ ì˜ìƒ: S/s ë˜ëŠ” ì•„ëž˜ í™”ì‚´í‘œ (2621440)
            if key in (ord('s'), ord('S'), 2621440):
                next_index = (self.current_index + 1) % len(self.videos)
                self.transition_to_video(cap, next_index, 'down')
                cap.release()
                cap = cv2.VideoCapture(self.videos[next_index])
                total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
                self.current_index = next_index
                paused = False
                print(f"â†’ {os.path.basename(self.videos[self.current_index])}")
            
            # ì´ì „ ì˜ìƒ (w ë˜ëŠ” ìœ„ í™”ì‚´í‘œ)
            # ì†Œë¬¸ìž/ëŒ€ë¬¸ìž ëª¨ë‘ í™•ì¸, í™”ì‚´í‘œëŠ” ë‹¤ì–‘í•œ ì½”ë“œ ì‹œë„
            # ì´ì „ ì˜ìƒ: W/w ë˜ëŠ” ìœ„ í™”ì‚´í‘œ (2490368)
            elif key in (ord('w'), ord('W'), 2490368):
                prev_index = (self.current_index - 1) % len(self.videos)
                self.transition_to_video(cap, prev_index, 'up')
                cap.release()
                cap = cv2.VideoCapture(self.videos[prev_index])
                total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
                self.current_index = prev_index
                paused = False
                print(f"â† {os.path.basename(self.videos[self.current_index])}")
            
            # ì¼ì‹œì •ì§€/ìž¬ìƒ
            elif key in (32, ord(' ')):  # Space
                paused = not paused
                print("â¸ ì¼ì‹œì •ì§€" if paused else "â–¶ ìž¬ìƒ")
            
            # UI í† ê¸€
            elif key in (ord('h'), ord('H')):
                self.show_ui = not self.show_ui
                print(f"UI {'í‘œì‹œ' if self.show_ui else 'ìˆ¨ê¹€'}")
            
            # ì¢…ë£Œ
            elif key in (ord('q'), ord('Q')):
                print("\ní”„ë¡œê·¸ëž¨ ì¢…ë£Œ")
                break
        
        cap.release()
        cv2.destroyAllWindows()
    
    def transition_to_video(self, current_cap, next_index, direction):
        """ë¹„ë””ì˜¤ ì „í™˜ íš¨ê³¼"""
        # í˜„ìž¬ í”„ë ˆìž„
        current_frame = self.get_frame(current_cap, self.display_size)
        if current_frame is None:
            return
        
        # ë‹¤ìŒ ë¹„ë””ì˜¤ì˜ ì²« í”„ë ˆìž„
        next_cap = cv2.VideoCapture(self.videos[next_index])
        next_frame = self.get_frame(next_cap, self.display_size)
        next_cap.release()
        
        if next_frame is None:
            return
        
        # ì „í™˜ ì• ë‹ˆë©”ì´ì…˜ (transitions ëª¨ë“ˆì˜ Transition ì‚¬ìš©)
        for i in range(self.transition_frames):
            progress = (i + 1) / self.transition_frames
            # Ease-out íš¨ê³¼ (ë¶€ë“œëŸ¬ìš´ ê°ì†)
            progress = 1 - (1 - progress) ** 3

            transition_frame = self.transition.render(
                current_frame, next_frame, progress, direction=direction
            )
            cv2.imshow('Video Player', transition_frame)
            cv2.waitKey(16)  # ~60fps